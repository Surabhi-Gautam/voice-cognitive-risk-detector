
# ğŸ§  Voice-Based Cognitive Decline Detection Pipeline

## ğŸ“Œ Overview

This project analyzes **speech audio files** to extract **NLP and acoustic features**, applies **machine learning** to detect anomalies, and visualizes trends that may indicate **cognitive decline**.  
It's built using Whisper, Librosa, Scikit-learn, and runs fully in Python.

---

## ğŸ“‚ Project Structure

```
voice-risk-detector/
â”œâ”€â”€ cognitive_decline_pipeline.ipynb  # Main notebook
â”œâ”€â”€ cognitive_risk_report.csv         # Output CSV with risk scores
â”œâ”€â”€ your_audio_dataset.zip            # Example audio input (not uploaded here)
â”œâ”€â”€ README.md                         # Project documentation
â””â”€â”€ requirements.txt                  # All dependencies
```

---

## ğŸš€ Features

- ğŸ—£ï¸ Transcribes audio using [Whisper](https://github.com/openai/whisper)
- ğŸ“Š Extracts NLP features: hesitation, word count, sentence length
- ğŸ§ Extracts audio features: pitch variability, tempo, duration
- ğŸ§ª Uses Isolation Forest to flag cognitive risk
- ğŸ“ˆ Visualizes patterns via Seaborn plots
- ğŸ§° Optional: API-ready risk scoring function

---

## ğŸ“ How to Run

1. **Clone the repo:**
   ```bash
   git clone https://github.com/your-username/voice-cognitive-risk-detector.git
   cd voice-cognitive-risk-detector
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the notebook:**
   Open `cognitive_decline_pipeline.ipynb` in Jupyter Notebook or VSCode.

4. **Provide your own `.zip` of `.wav` files** or test with provided structure.

---

## ğŸ”¬ Deliverables

âœ… Clean and reproducible Python notebook  
âœ… Sample visualizations of extracted features and anomalies  
âœ… Optional API function to score risk from a single audio input

---

## ğŸ“ˆ Sample Output

| File                          | Pitch Std | Tempo | Risk Flag |
|------------------------------|-----------|-------|-----------|
| 03-01-01-01-01-01-01.wav      | 23.2      | 92.3  | -1 (Risk) |
| 03-01-01-01-01-02-01.wav      | 5.4       | 120.5 | 1 (Normal)|

> Pairplot of features shows separation of potential anomalies.

---

## ğŸ§ª Risk Scoring Function (Optional)

You can use this function in a web app or API:

```python
def score_audio_file(file_path):
    text, _ = transcribe_audio(file_path)
    nlp = extract_nlp_features(text)
    audio = extract_audio_features(file_path)
    features = {**nlp, **audio}
    return model.predict([scaler.transform([list(features.values())])])
```

---

## ğŸ§¾ Requirements

- Python 3.9+
- whisper
- librosa
- numpy
- pandas
- matplotlib
- seaborn
- scikit-learn

Install via:
```bash
pip install -r requirements.txt
```

---

## ğŸ’¡ Future Enhancements

- Add a Streamlit web interface
- Track cognitive change over time per speaker
- Support more audio formats + voice diarization

---

## ğŸ“¬ Contact

Made with â¤ï¸ for Daksh'25 STEM Hackathon  
Project by **[Your Name]**  
[LinkedIn] | [GitHub]
